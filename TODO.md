# TODO


General Theme: Attempt to find a way to fit the necessary contextual information into the limit context size for the T5 model. 

## General

- Multi-gpu training
- Sharing the tuned models
- Evaluation
- Code for training and evaluation
- Baseline???
- Metrics (is rouge enough for lay sum?)
- tuning on elife + on plos or separately?
- Optimum parameters for LexRank
  - Number of sentences
  - Have to consider max token length of 4096 (input length + max output length = 4096)
  - How will it impact traning time?

## Vlad

- 

## Ahmed

- 

## Marc

- 
